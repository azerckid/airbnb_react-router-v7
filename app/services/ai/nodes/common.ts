
import { ChatOpenAI } from "@langchain/openai";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import { StringOutputParser } from "@langchain/core/output_parsers";
import { type AgentState } from "./types";
import { searchRooms } from "../core.server";
import { initAutoPlanNode } from "./auto-plan";

const openAIKey = process.env.OPENAI_API_KEY;

export async function emergencyNode(state: AgentState) {
    // Redirect to InitAutoPlan
    return initAutoPlanNode(state);
}

export async function budgetNode(state: AgentState) {
    // Redirect to InitAutoPlan
    return initAutoPlanNode(state);
}

export async function flightNode(state: AgentState) {
    const model = new ChatOpenAI({ modelName: "gpt-4o-mini", openAIApiKey: openAIKey });
    return { answer: "Flight Search Logic here..." };
}

export async function greeterNode(state: AgentState) {
    const model = new ChatOpenAI({ modelName: "gpt-4o-mini", openAIApiKey: openAIKey, temperature: 0.7 });
    const response = await ChatPromptTemplate.fromTemplate("Reply warmly to: {query}").pipe(model).pipe(new StringOutputParser()).invoke({ query: state.query });
    return { answer: response };
}

export async function searcherNode(state: AgentState) {
    const docs = await searchRooms(state.query);
    const context = docs.map((d: any) => d.pageContent).join("\n");
    const model = new ChatOpenAI({ modelName: "gpt-4o-mini", openAIApiKey: openAIKey });
    const response = await ChatPromptTemplate.fromTemplate(`Context: {context} \n\n Answer {query}`).pipe(model).pipe(new StringOutputParser()).invoke({ context, query: state.query });
    return { answer: response, context };
}
